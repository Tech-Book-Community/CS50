# èª²ç¨‹é€£çµ
[CS50 Artificial Intelligence](https://cs50.harvard.edu/x/2024/weeks/ai/#artificial-intelligence)
[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/6X58aP7yXC4/0.jpg)](https://www.youtube.com/watch?v=6X58aP7yXC4)

# 1. Image Generation
- [HackMDå¥½è®€ç‰ˆ](https://hackmd.io/@HWjmtqGJQRmj4pwClBcCKg/HkQKvTWIC)

> åƒè€ƒè³‡æ–™ï¼š
>- [åŸºæ–¼ Diffusion Models çš„ç”Ÿæˆåœ–åƒæ¼”ç®—æ³•](https://d246810g2000.medium.com/%E5%9F%BA%E6%96%BC-diffusion-models-%E7%9A%84%E7%94%9F%E6%88%90%E5%9C%96%E5%83%8F%E6%BC%94%E7%AE%97%E6%B3%95-984212710610)
>- [AIAIART #7](https://colab.research.google.com/drive/1NFxjNI-UIR7Ku0KERmv7Yb_586vHQW43?usp=sharing#scrollTo=g7btoXL7Im7M)
>- [åŸå§‹è«–æ–‡:Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)

## å¸¸è¦‹åœ–ç‰‡ç”Ÿæˆ
![](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/generative-overview.png)
- Autoencoder [2006]
- Variational Autoencoder (VAE) [2014]
- Flow-based models
- GAN [2014]
- PixelRNN [2016]
- Diffusion [2020]

## Defusion Model
Defusion Model æ˜¯æ¨¡ä»¿Markov chainï¼Œåˆ©ç”¨å¸¸æ…‹åˆ†ä½ˆ(é«˜æ–¯åˆ†ä½ˆ)é€æ¼¸å°ä¸€å¼µåœ–ç‰‡å¢åŠ é›œè¨Šï¼Œç›´åˆ°çœ‹ä¸åˆ°åŸå§‹çš„åœ–ç‰‡(ä¸‹åœ–çš„q)ï¼Œå†åˆ©ç”¨æ¨¡å‹ä¸€æ­¥ä¸€æ­¥æŠŠåœ–ç‰‡é‚„åŸå›ä¾†(ä¸‹åœ–çš„p)
![image](https://hackmd.io/_uploads/BJz50T7LR.png)

å¯ä»¥çœ‹ä¸‹å·¦é€™å¼µåœ–é€æ¼¸å¾é›œè¨Šä¸­ç”Ÿå‡ºä¸€å¼µåœ–ã€‚
<table>
  <tr>
    <td style="text-align: center;">
      <img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*4GmL_x9gzQu3uiH8JKdfaQ.gif" alt="Image 1" style="max-width:97%;">
      <p>ç”Ÿæˆéç¨‹</p>
    </td>
    <td style="text-align: center;">
      <img src="https://truth.bahamut.com.tw/s01/202304/4adfdcb747b978c794f5709339986662.JPG" alt="Image 2" style="max-width:97%;">
      <p>æˆ‘çš„trainå£æ‰çš„ç‰ˆæœ¬</p>
    </td>
  </tr>
</table>


### Diffusion process (æ“´æ•£éç¨‹)
ä¸‹é¢æ˜¯çš„æ„æ€æ˜¯ï¼Œæˆ‘å€‘æœƒé€æ­¥å°ä¸€å¼µåœ–ç‰‡åŠ ä¸Šå¸¸æ…‹åˆ†é…çš„é›œè¨Šï¼Œé€™å€‹æ­¥é©Ÿç¸½å…±æœƒåšTæ¬¡ï¼Œå…¶ä¸­çš„ä¸€æ¬¡å«åštã€‚`Beta_t`æ˜¯ä¸€å€‹æœƒéš¨è‘—tè¶Šå¤§è€Œå¢åŠ çš„å€¼ï¼Œè€Œé›œè¨Šçš„å¸¸æ…‹åˆ†é…çš„å¹³å‡æ•¸(mean)æ˜¯`Beta_t`*ä¸Šä¸€æ­¥é©Ÿt-1çš„åœ–ç‰‡, è®Šç•°æ•¸(var)æ˜¯`Beta_t`ï¼Œå¯ä»¥ç®—å‡ºé›œè¨Šeps, æ¥è‘—æ–°çš„åœ–ç‰‡æœƒæ˜¯`main + âˆšvar*eps`ã€‚

æˆ‘å€‘æ¨¡å‹è¦è¨“ç·´çš„å…¶å¯¦æ˜¯çµ¦å®šä¸€å¼µè¢«é›œè¨Šæ±¡æŸ“çš„`X_t`ï¼Œè¦æ±‚æ¨¡å‹å¹«æˆ‘å€‘é æ¸¬å‡ºæ˜¯ä»€éº¼é›œè¨Šæ±¡æŸ“ä»–ï¼Œä¹Ÿå°±æ˜¯é æ¸¬`eps`:

> å…¬å¼


![åœ–ç‰‡](https://github.com/CAFECA-IO/KnowledgeManagement/assets/55581222/06a6f2ab-25a4-4e41-827a-a6e4107fc17c)




```python
n_steps = 100
beta = torch.linspace(0.0001, 0.04, n_steps)

def q_xt_xtminus1(xtm1, t):
  # gat
  mean = gather(1. - beta, t) ** 0.5 * xtm1 # âˆš(1âˆ’Î²t)*xtm1
  var = gather(beta, t) # Î²t I
  eps = torch.randn_like(xtm1) # Noise shaped like xtm1
  return mean + (var ** 0.5) * eps


def gather(consts: torch.Tensor, t: torch.Tensor):
    """
    Gather consts for $t$ and reshape to feature map shape
    ç”¨ä¾†æå–ä¸€å€‹tensorä¸­ç¬¬tå€‹å€¼ï¼Œä¸¦éŒ¢reshape
    
    """
    c = consts.gather(-1, t)
    return c.reshape(-1, 1, 1, 1)
```

### Reverse process (é€†æ“´æ•£éç¨‹)

ä¸Šé¢èªªåˆ°æ¨¡å‹éœ€è¦çµ¦å®šåœ–ç‰‡`x_t`ï¼Œé æ¸¬é›œè¨Š`eps`ï¼Œå¯¦éš›ä¸Šæ˜¯è¦è®“æ¨¡å‹å­¸æœƒç”¢ç”Ÿ`eps`çš„å¸¸æ…‹åˆ†é…çš„å¹³å‡å€¼å’Œæ¨™æº–å·®ã€‚

æœ‰äº†ä¸Šé¢çš„`beta_t`ï¼Œå¯ä»¥ç®—å‡º`alpha_t = 1 - beta_t`, `alpha_bar_t = å¾ t=0 é€£ä¹˜åˆ°t=t`ï¼Œæ¥è‘—æŒ‰ä¸‹é¢æ­¥é©Ÿç®—å‡ºï¼š
1. é›œè¨Šçš„ä¿‚æ•¸ eps_coef = `(1-alpha_t )/ âˆš(1-alpha_bar_t)`
2. å¹³å‡mean = `(1/(âˆšalpha_t))*(x_t - eps_coef * noise)`
3. var: å°±æ˜¯`beta_t`
4. æ–°çš„é›œè¨Šeps: ç”¨torchç”Ÿæˆéš¨æ©Ÿæ•¸
5. æ–°çš„åœ–ç‰‡ `main + âˆšvar*eps`

> å…¬å¼ï¼š


![åœ–ç‰‡](https://github.com/CAFECA-IO/KnowledgeManagement/assets/55581222/c5c14395-b96e-4b2c-85de-f127d00149f0)



> ç¨‹å¼ç¢¼ï¼š

```python
# Set up some parameters
n_steps = 100
beta = torch.linspace(0.0001, 0.04, n_steps).cuda()
alpha = 1. - beta
alpha_bar = torch.cumprod(alpha, dim=0)

def p_xt(xt, noise, t):
  """
  x_t:è¢«æ±¡æŸ“çš„åœ–ç‰‡
  noiseï¼šæ¨¡å‹çœ‹è‘—x_té æ¸¬å‡ºä¾†çš„é›œè¨Š
  t:ç¾åœ¨æ˜¯ç¬¬å¹¾æ­¥é©Ÿ
  """
  alpha_t = gather(alpha, t)
  alpha_bar_t = gather(alpha_bar, t)
  eps_coef = (1 - alpha_t) / (1 - alpha_bar_t) ** .5
  mean = 1 / (alpha_t ** 0.5) * (xt - eps_coef * noise) # Note minus sign
  var = gather(beta, t)
  eps = torch.randn(xt.shape, device=xt.device)
  return mean + (var ** 0.5) * eps 
```

### Algorithm æ¼”ç®—æ³•
![image](https://hackmd.io/_uploads/HJw4C6Q8C.png)

#### Loss Function
å­¸ç¿’çš„æ™‚å€™æœƒä½¿ç”¨ä¸‹é¢é€™å€‹loss functionä¾†è¨ˆç®—ï¼Œå…¶å¯¦å°±æ˜¯ç®—å‡ºæ±¡æŸ“`x_t`åœ–ç‰‡çš„é›œè¨Š`eps_t`èˆ‡æ¨¡å‹é æ¸¬çš„é›œè¨Š`pred_noise_t`å¹³æ–¹å·®çš„å¹³æ–¹ (mse)

![åœ–ç‰‡](https://github.com/CAFECA-IO/KnowledgeManagement/assets/55581222/1775ade6-5e52-4136-bba0-884d27758fa5)

#### Training
é‡è¤‡ä»¥ä¸‹4å€‹æ­¥é©Ÿç›´åˆ°lossé™ä½
1.è¨“ç·´æ™‚å…ˆå¾æˆ‘å€‘æƒ³è¨“ç·´çš„åœ–ç‰‡é›†(`q(x_theata`)ä¸­æŒ‘å‡ºä¸€å¼µ `x_theata`
2.è¨­å®šç¸½è¨“ç·´æ­¥é©Ÿæ•¸å¤§T(ä¹Ÿå°±æ˜¯ä¸Šé¢è¨­å®šçš„`n_step`)ï¼Œä¸­**éš¨æ©Ÿ**æŒ‘æœ±ä¸€å€‹æ­¥é©Ÿåš
3.å…ˆç”¨å¸¸æ…‹åˆ†ä½ˆéš¨æ©Ÿå‡ºä¸€å€‹é›œè¨Š`eps`
4.ç”¨ä¸Šé¢çš„loss functionç®—å‡º`eps`èˆ‡æ¨¡å‹é æ¸¬çš„é›œè¨Š`pred_noise`çš„å¹³æ–¹å·®çš„å¹³æ–¹ï¼Œç„¶å¾Œåšgradient descent

<div style="display: flex-ã„ã„ ; justify-content: space-around;">
  <div style="text-align: left; width: 100%;;">
    <b>Algorithm 1</b> Training
    <pre>
1: repeat
2:   <b>x</b><sub>0</sub> ~ <i>q</i>(<b>x</b><sub>0</sub>)
3:   <i>t</i> ~ Uniform({1, ..., T})
4:   <b>Îµ</b> ~ <i>ğ’©</i>(0, <b>I</b>)
5:   Take gradient descent step on
         âˆ‡<sub>Î¸</sub> || <b>Îµ</b> - <b>Îµ</b><sub>Î¸</sub>(âˆš<span style="text-decoration: overline;">Î±</span><sub>t</sub><b>x</b><sub>0</sub> + âˆš1 - <span style="text-decoration: overline;">Î±</span><sub>t</sub><b>Îµ</b>, <i>t</i>) ||<sup>2</sup>
6: until converged
    </pre>
  </div>
</div>


#### Sampling

è¨“ç·´å¥½ä¹‹å¾Œå°±å¯ä»¥ä¾†ç”¢åœ–äº†ï¼Œç”¢åœ–æµç¨‹å¦‚ä¸‹ï¼š
1. å…ˆç²å¾—ä¸€å€‹é›œè¨Šï¼Œå°±åš`x_T`
2. åŸ·è¡Œå¤§T(n_step)æ¬¡å»å™ªå‹•ä½œï¼Œä»¥ä¸‹ç‚ºloop
    1. ä½¿ç”¨è¨“ç·´å¥½çš„modelç”¢ç”Ÿé æ¸¬çš„é›œè¨Š`pred_eps`
    1. ä½¿ç”¨[Reverse process (é€†æ“´æ•£éç¨‹)](#Reverse-process-é€†æ“´æ•£éç¨‹)çš„å…¬å¼ï¼Œå¹«åœ–ç‰‡é™å™ªï¼Œä¸¦é‚„è¦åŠ ä¸Šä¸€å€‹å°é›œè¨Š
3. loopå®Œä¹‹å¾Œåœ–ç‰‡ç”¢å‡º 

<div style="display: flex-ã„ã„ ; justify-content: space-around;">
  <div style="text-align: left; width: 100%;">
    <b>Algorithm 2</b> Sampling
    <pre>
1: <b>x</b><sub>T</sub> ~ <i>ğ’©</i>(0, <b>I</b>)
2: for <i>t</i> = T, ..., 1 do
3:   <b>z</b> ~ <i>ğ’©</i>(0, <b>I</b>) if <i>t</i> > 1, else <b>z</b> = 0
4:   <b>x</b><sub>t-1</sub> = <sup>1</sup>/<sub>âˆšÎ±<sub>t</sub></sub> (<b>x</b><sub>t</sub> - <sup>1 - Î±<sub>t</sub></sup>/<sub>âˆš1 - <span style="text-decoration: overline;">Î±</span><sub>t</sub></sub> <b>Îµ</b><sub>Î¸</sub>(<b>x</b><sub>t</sub>, <i>t</i>)) + Ïƒ<sub>t</sub><b>z</b>
5: end for
6: return <b>x</b><sub>0</sub>
    </pre>
  </div>
</div>

### UNet æ¨¡å‹

> åƒè€ƒè³‡æ–™
>- [UNet åŸå§‹è«–æ–‡:U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)
>- [ConvTranspose2dåŸç†ï¼Œæ·±åº¦ç½‘ç»œå¦‚ä½•è¿›è¡Œä¸Šé‡‡æ ·ï¼Ÿ](https://blog.csdn.net/qq_27261889/article/details/86304061)

U Net æ˜¯ç”¨ä¾†é æ¸¬é›œè¨Š `pred_eps`çš„æ¨¡å‹æœ¬é«”ï¼Œä»–å¯ä»¥è¼¸å…¥å…©å€‹å€¼ï¼š
1. ç”¨ä¾†é æ¸¬çš„è¢«æ±¡æŸ“çš„åœ–ç‰‡`x_t`
2. ç¾åœ¨æ˜¯ç¬¬å¹¾å€‹æ­¥é©Ÿt

æ­¥é©Ÿæ˜¯
1. down: 2æ¬¡çš„ 3\*3 convolution æ­é…ä¸€æ¬¡2\*2 max poolï¼Œå…±åŸ·è¡Œ4æ¬¡
2. middle(bottom)ï¼Œå…©æ¬¡çš„convolutionï¼Œåœ¨é€™è£¡è¦åŠ æ•¸æ­¥é©Ÿtçš„embeddingè³‡è¨Šï¼Œæ¨¡å‹æ‰æœƒçŸ¥é“ç¾åœ¨åœ¨ç¬¬å¹¾æ­¥é©Ÿ
3. up:2æ¬¡çš„ 3\*3 convolution æ­é…ä¸€æ¬¡2\*2 up-conv(é€†convolution)ï¼Œå…±åŸ·è¡Œ4æ¬¡
![image](https://hackmd.io/_uploads/HJDoCe4LA.png)

# 2. Deep Learning
> åƒè€ƒè³‡æ–™
> - [æå®æ¯…. 2016d. ML Lecture 6: Brief Introduction of Deep Learning. YouTube](https://www.youtube.com/watch?v=Dr-WRlEFefw.)
> - [æå®æ¯…. 2016g. ML Lecture 11: Why Deep? YouTube.](https://www.youtube.com/watch?v=XsC9byQkUH8)
> - [æå®æ¯…. 2016d. ML Lecture 6: Brief Introduction of Deep Learning. YouTube.](https://www.youtube.com/watch?v=Dr-WRlEFefw)
> - [æå®æ¯…. 2017a. ML Lecture 5: Logistic Regression. YouTube.](https://www.youtube.com/watch?v=hSXFuypLukA)
> - [æå®æ¯…. 2016a. ML Lecture 1: Regression - Case Study. YouTube.](https://tdr.lib.ntu.edu.tw/jspui/bitstream/123456789/8399/1/U0001-1204202115134100.pdf)
> - [Glorot, X., and Y. Bengio. 2010. Understanding the difficulty of training deep feedforward neural
networks. ](https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)

## åç¨±çš„ç”±ä¾†
1958å¹´ï¼ŒFrank Rosenblatt æå‡º Perceptron æ¼”ç®—æ³•ï¼Œç”¨æ–¼ç·šæ€§åˆ†é¡ã€‚1962å¹´ï¼ŒMarvin Minsky æ‰¹è©•å…¶å±€é™æ€§ï¼Œå°è‡´ç ”ç©¶ç†±æ½®è¿…é€Ÿå¹³æ¯ã€‚1980å¹´ä»£ä¸­æœŸï¼ŒMultilayer Perceptronï¼ˆå¤šå±¤æ„ŸçŸ¥å™¨ï¼‰è¢«æå‡ºï¼Œå¯¦éš›ä¸Šæ˜¯å¤šå±¤ Logistic Model çš„é€£æ¥ï¼Œè¢«ç¨±ç‚º Neural Networkï¼ˆç¥ç¶“ç¶²è·¯ï¼‰ã€‚1986å¹´ï¼ŒRumelhart ç­‰æå‡º Back-propagation æ¼”ç®—æ³•ï¼Œå¯èª¿æ•´ç¥ç¶“ç¶²è·¯ä¸­å„å–®å…ƒçš„æ¬Šé‡ã€‚ç„¶è€Œï¼Œéš±è—å±¤è¶…éä¸‰å±¤æ™‚æ•ˆæœä¸ä½³ï¼Œ1989å¹´ï¼Œå¤šæ•¸å­¸è€…èªç‚ºä¸€å±¤éš±è—å±¤è¶³å¤ ã€‚

1999å¹´å¾Œï¼Œéš¨è‘—GPUçš„ç™¼å±•ï¼Œè¨“ç·´å¤šå±¤éš±è—å±¤è®Šå¾—å¯èƒ½ï¼ŒMultilayer Perceptron è¢«é‡æ–°å‘½åç‚º Deep Learningï¼ˆæ·±åº¦å­¸ç¿’ï¼‰ã€‚2006å¹´ï¼ŒHintonç­‰äººæå‡ºä½¿ç”¨ Restricted Boltzmann machines (RBM) ä¾†åˆå§‹åŒ–æ·±åº¦å­¸ç¿’çš„æ¬Šé‡ï¼Œå¸å¼•äº†è¨±å¤šç ”ç©¶è€…çš„é—œæ³¨ã€‚ä¸€äº›äººèªç‚ºä½¿ç”¨RBMæ‰ç®—æ˜¯æ·±åº¦å­¸ç¿’ï¼Œä½†éš¨è‘—ç ”ç©¶æ·±å…¥ï¼Œç™¼ç¾ä¸éœ€è¦RBMä¹Ÿèƒ½è¨“ç·´æ·±åº¦å­¸ç¿’æ¨¡å‹ã€‚å› æ­¤ï¼ŒDeep Learning èˆ‡ Multilayer Perceptronï¼ˆNeural Networkï¼‰æˆç‚ºåŒä¸€ç¨®æ¼”ç®—æ³•çš„ä¸åŒåç¨±ï¼Œã€Œæ·±åº¦å­¸ç¿’ã€èˆ‡ã€Œç¥ç¶“ç¶²çµ¡ã€å¸¸è¢«äº¤äº’ä½¿ç”¨ã€‚

## æ·±åº¦å­¸ç¿’5å€‹çµ„ä»¶

### 1. Activation Function

Activation function æ˜¯æ·±åº¦å­¸ç¿’ä¸­æœ€åŸºæœ¬çš„å–®ä½ï¼Œå¯ä»¥æƒ³åƒå®ƒæ˜¯ç¥ç¶“ç¶²è·¯ä¸­çš„
ä¸€å€‹ç¯€é»(node)ï¼ŒåŸ·è¡Œæœ€ç°¡å–®çš„éç·šæ€§è½‰æ›ã€‚ å¸¸è¦‹çš„æœ‰Sigmoid å’Œ ReLUç­‰ï¼š

> **Sigmoid å‡½æ•¸:**


$$
\sigma(x) = \frac{1}{1 + e^{-x}}
$$


> **ReLU å‡½æ•¸:**


$$
\text{ReLU}(x) = \max(0, x)
$$

Activation function å¯ä»¥ç”¢ç”Ÿç›¸ç•¶æ–¼é‚è¼¯é‹ç®—å­çš„æ•ˆæœï¼Œèˆ‰ä¾‹ä¾†èªªï¼Œå¦‚æœæœ‰å››çš„é»ï¼Œåˆ†åˆ¥ç‚º(0,0)ã€(1,0)ã€(0,1)ã€(1,1)ã€‚å¦‚æœè¦å°‡(0,0)èˆ‡(1,1)åˆ†ç‚ºä¸€é¡ï¼Œ(1,0)èˆ‡(0,1)åˆ†ç‚ºå¦ä¸€é¡ï¼Œæœƒç™¼ç¾è‹¥å–®ç´”ä½¿ç”¨ä¸€æ¬¡æ–¹ç¨‹æœƒä¸èƒ½è¼•æ˜“å€åˆ†ã€‚

ä½†å¦‚æœæˆ‘å€‘ç”¨ä»¥ä»¥ä¸‹å…©å€‹Functionåšè½‰æ›

$$
\text{w} = \max(0, x - 0.5 y)
$$

$$
\text{z} = \max(0, -0.9x + y)
$$
è½‰æ›å¾Œçš„å››å€‹é»åˆ†åˆ¥ç‚º(0,0)ã€(0.5,0.1)ã€(1,0)ã€(0,1)ï¼Œå°±å¯ä»¥è¢«ä¸€æ¬¡æ–¹ç¨‹åˆ†æˆå…©é‚Šã€‚

<table>
  <tr>
    <td style="text-align: center;">
      <img src="https://hackmd.io/_uploads/SyXMZjjU0.png" alt="Image 1" style="max-width:95%;">
      <p>è½‰æ›å‰</p>
    </td>
    <td style="text-align: center;">
      <img src="https://hackmd.io/_uploads/SJY7Wss8R.png" alt="Image 2" style="max-width:100%;">
      <p>è½‰æ›å¾Œ</p>
    </td>
  </tr>
</table>


### 2. æ·±åº¦å­¸ç¿’æ¶æ§‹

æ·±åº¦å­¸ç¿’æ¶æ§‹å¯ä»¥éˆæ´»è®ŠåŒ–ä»¥æ»¿è¶³ä¸åŒéœ€æ±‚ã€‚é€™é‚Šä½¿ç”¨æœ€åŸºç¤çš„ Fully Connected Feedforward Network æ¶æ§‹ï¼Œç”± Input Layerã€Output Layer å’Œä»»æ„æ•¸é‡çš„ Hidden Layer çµ„æˆã€‚

1. **Input Layer**ï¼šé€™ä¸€å±¤ä¸¦ä¸æ˜¯çœŸæ­£çš„ä¸€å±¤ï¼Œè€Œæ˜¯è¡¨ç¤ºè¼¸å…¥å‘é‡ã€‚æ¯å€‹è‡ªè®Šæ•¸éƒ½æœƒè¼¸å…¥åˆ°ä¸‹ä¸€å±¤çš„æ‰€æœ‰ç¯€é»ä¸­ã€‚

2. **Hidden Layer**ï¼šé€™å±¤æ˜¯ç”±ä»»æ„æ•¸é‡çš„ Activation Function çµ„æˆçš„ï¼Œå¯ä»¥æœ‰å¤šå±¤ã€‚æ¯å±¤çš„ç¯€é»æ•¸é‡å’Œä½¿ç”¨çš„ Activation Function å¯ä»¥ä¸åŒã€‚ä¾‹å¦‚ï¼Œç¬¬ä¸€å±¤å¯ä»¥ä½¿ç”¨5000å€‹ Sigmoid å‡½æ•¸ï¼Œè€Œç¬¬äºŒå±¤å¯ä»¥ä½¿ç”¨3000å€‹ ReLU å‡½æ•¸ã€‚å¾ Input Layer å¾—åˆ°çš„è‡ªè®Šæ•¸åœ¨æ¯å€‹ç¯€é»æœƒç”¢ç”Ÿä¸€å€‹å€¼ï¼Œé€™äº›å€¼ä½œç‚ºæ–°çš„è‡ªè®Šæ•¸è¼¸å…¥åˆ°ä¸‹ä¸€å±¤ã€‚æ¯å€‹ Hidden Layer çš„è¼¸å‡ºéƒ½æœƒè¼¸å…¥åˆ°ä¸‹ä¸€å±¤çš„æ‰€æœ‰ç¯€é»ä¸­ï¼Œæœ€çµ‚è¼¸å‡ºåˆ° Output Layerã€‚

3. **Output Layer**ï¼šé€™ä¸€å±¤ä½œç‚ºåˆ†é¡å™¨ï¼Œå°‡ç¶“é Hidden Layer éç·šæ€§è½‰æ›çš„è³‡æ–™åˆ†é¡ã€‚ä¾‹å¦‚ï¼Œç¶“éå¤šå±¤éç·šæ€§è½‰æ›å¾Œï¼Œè³‡æ–™é»æœƒè½‰æ›æˆå®¹æ˜“è¢«åˆ†é¡çš„å‹æ…‹ï¼Œæ‰¾å‡ºè³‡æ–™çš„ç‰¹å¾µ(Feature)ï¼Œå†åˆ©ç”¨ Output Layer æŠŠè³‡æ–™åˆ†é¡æˆå¤šå€‹é¡åˆ¥ã€‚å¸¸ç”¨çš„åˆ†é¡å‡½æ•¸æ˜¯ Softmax functionï¼Œå®ƒå°‡ hidden layer ä¸­çš„è³‡æ–™å£“ç¸®åˆ° 0 åˆ° 1 ä¹‹é–“ï¼Œè¨ˆç®—å‡ºæ¯å€‹é¡åˆ¥çš„å¾Œé©—æ©Ÿç‡ï¼Œæœ€å¤§å€¼å°æ‡‰çš„é¡åˆ¥å³ç‚ºé æ¸¬é¡åˆ¥ã€‚

$$
\text{Softmax}(x_i) = \frac{e^{x_i}}{\sum\limits_{j=1}^N e^{x_j}}
$$

5. **Fully Connected Feedforward Network**ï¼šé€™æ˜¯æœ€å¸¸è¦‹çš„é€£æ¥å„å±¤çš„æ–¹æ³•ã€‚æ¯å€‹ç¯€é»çš„è¼¸å‡ºéƒ½æœƒå‚³éåˆ°ä¸‹ä¸€å±¤çš„æ‰€æœ‰ç¯€é»ï¼Œè€Œæ¯å€‹ç¯€é»ä¹Ÿæœƒä½¿ç”¨ä¸Šä¸€å±¤æ‰€æœ‰ç¯€é»çš„è¼¸å‡ºã€‚é€™ç¨®çµæ§‹è¢«ç¨±ç‚º Fully Connectedï¼Œè³‡æ–™å¾ Input Layer å‚³éåˆ° Hidden Layerï¼Œå†å‚³éåˆ° Output Layerï¼Œå‘ˆç¾é †å‘çµæ§‹ã€‚

é€™ç¨®æ¶æ§‹å…è¨±ä»»æ„æ”¹è®Šä»¥é©æ‡‰ä¸åŒçš„éœ€æ±‚ï¼Œä¸¦æä¾›äº†å¼·å¤§çš„éˆæ´»æ€§å’Œå¯æ“´å±•æ€§ï¼Œä½¿å…¶æˆç‚ºæ·±åº¦å­¸ç¿’é ˜åŸŸçš„åŸºç¤ã€‚

<div align="center">
  <div>
    <img src="https://hackmd.io/_uploads/Hk94VsjU0.png" alt="Image 1" style="max-width:95%;">
    <p>Fully Connected Feedforward Network</p>
  </div>
</div>


### 3. Loss Function

åœ¨æ·±åº¦å­¸ç¿’ä¸­ï¼Œè©•ä¼°æ¨¡å‹å¥½å£éœ€è¦ä½¿ç”¨ Loss Functionã€‚Loss Function é€šéæ¯”è¼ƒæ¨¡å‹é æ¸¬çµæœèˆ‡çœŸå¯¦è³‡æ–™ä¾†è¨ˆç®—ä¸€å€‹åˆ†æ•¸ï¼ˆLossï¼‰ï¼Œåˆ†æ•¸è¶Šä½è¡¨ç¤ºé æ¸¬çµæœè¶Šæ¥è¿‘çœŸå¯¦è³‡æ–™ï¼Œæ¨¡å‹æ€§èƒ½è¶Šå¥½ã€‚å¸¸ç”¨çš„ Loss Function åŒ…æ‹¬ Cross Entropyï¼Œç‰¹åˆ¥æ˜¯åœ¨åˆ†é¡ä»»å‹™ä¸­ã€‚

Cross Entropy çš„å„ªå‹¢åœ¨æ–¼ç•¶æ¨¡å‹é æ¸¬èˆ‡çœŸå¯¦è³‡æ–™ç›¸å·®è¼ƒå¤§æ™‚ï¼Œå¾®åˆ†å¾Œçš„æ–œç‡è¼ƒå¤§ï¼Œæœ‰åŠ©æ–¼è¨“ç·´ï¼Œè€Œå¹³æ–¹å·®å…¬å¼åœ¨ç›¸åŒæƒ…æ³ä¸‹å‰‡è¼ƒå¹³ç·©ï¼Œä¸åˆ©æ–¼è¨“ç·´ã€‚Loss Function å¿…é ˆå¯å¾®ï¼Œä»¥ä¾¿ä½¿ç”¨ Gradient Descent æ‰¾å‡ºæœ€ç¬¦åˆçœŸå¯¦æƒ…æ³çš„æ¨¡å‹ã€‚æ ¹æ“šä¸åŒæƒ…æ³ï¼Œä¹Ÿå¯ä»¥é¸æ“‡å…¶ä»– Loss Function æˆ–è‡ªå®šç¾© Loss Functionã€‚

> Cross Entropy

$$
L = -\sum_{i=1}^{N} y_i \log(\hat{y}_i)
$$

<div align="center">
  <div>
    <img src="https://hackmd.io/_uploads/B1KWUiiIR.png" alt="Image 1" style="max-width:95%;">
    <p>ç´…è‰²ç‚ºå¹³æ–¹å·®ï¼Œé»‘è‰²ç‚º Cross Entropy</p>
  </div>
</div>

### 4. Gradient Descent

æƒ³åƒæ¨¡å‹ä¸­çš„æ¯å€‹æ¬Šé‡ (weight) ä»£è¡¨ç©ºé–“ä¸­çš„ä¸€è»¸ï¼ŒæŠŠæ‰€æœ‰æ¬Šé‡å¸¶å…¥ Loss Function ä¸­å½¢æˆé«˜ä½èµ·ä¼çš„ç©ºé–“ï¼Œæ¯å€‹é»è¡¨ç¤ºä¸€çµ„æ¬Šé‡è¨ˆç®—å‡ºçš„ Lossã€‚æœ€ä½³æ¨¡å‹æ“æœ‰æœ€ä½çš„ Lossï¼Œå³æ•´å€‹ç©ºé–“ä¸­æœ€åº•é»çš„ä½ç½®ã€‚è¨ˆç®—å…¨éƒ¨æ¬Šé‡çµ„åˆçš„ Loss æœƒè€—è²»å¤§é‡è³‡æºï¼Œå› æ­¤ä½¿ç”¨ Gradient Descent ä¾†æ‰¾å‡ºç­”æ¡ˆã€‚

Gradient Descent å¾ Loss çµ„æˆçš„æ³¢æµªä¸­é¸æ“‡ä¸€å€‹é»ï¼Œæœè‘—è©²é»æ–œç‡çš„åæ–¹å‘èµ°ä¸€æ­¥ï¼Œé‡è¤‡æ­¤æ­¥é©Ÿç›´åˆ°æ–œç‡ç‚º0çš„æœ€åº•é»ã€‚è¦å¾—åˆ°æ­¤æ–œç‡éœ€è¦æŠŠ Loss Function å°æ¯ä¸€å€‹æ¬Šé‡åšåå¾®åˆ†ï¼Œå¾—åˆ°çš„
å€¼çµ„æˆä¸€å€‹å‘é‡å°±å«åšæ¢¯åº¦(Gradient)ï¼Œå¯ç”¨ç¬¦è™Ÿâˆ‡è¡¨ç¤º

è€Œç‚ºäº†è¦æ±‚å¾—æœ€ä½å€¼ï¼Œéœ€è¦å°‡åŸæœ¬çš„æ¬Šé‡æ¸›å» Gradientï¼Œæ‰æœƒæœæœ€ä½å€¼å‰é€²ã€‚åŸå…ˆçš„é»å·®è·å¤ªé è€Œéåƒæœ€ä½é»å‰é€²ï¼Œæ–¼æ˜¯åœ¨æ¸› Gradient æ™‚æœƒä¹˜ä¸Šä¸€å€‹æ•¸ä¾†é™åˆ¶Gradient çš„æ­¥ä¼é•·åº¦ï¼Œé€™å€‹æ•¸ç¨±ä¹‹ç‚º Learning Rateï¼Œå¯ç”¨ç¬¦è™Ÿ Î· è¡¨ç¤ºã€‚ä»¥ä¸Šæ­¥é©Ÿå¯è¡¨ç¤ºå¦‚ä¸‹ï¼š

$$
w^{(T+1)} = w^{(T)} - \eta \nabla \text{Loss}(w^{(T)})
$$

é™¤äº†åŸºæœ¬çš„ Gradient Descentï¼Œé‚„æœ‰è¨±å¤šè®Šå½¢æ–¹æ³•ï¼Œå¦‚æ¯æ¬¡åªä½¿ç”¨ä¸€ç­†è³‡æ–™çš„ Stochastic Gradient Descentã€è™•ç†ä¸å‡è¡¡è‡ªè®Šæ•¸çš„ Adagradï¼Œçµåˆå‹•é‡æ¦‚å¿µçš„ Adamã€‚

### 5. Backpropagation

> åƒè€ƒå½±ç‰‡ï¼š[ML Lecture 7: Backpropagation](https://www.youtube.com/embed/ibJpTrp5mcE?si=ITgK5Ima4WK61AVT)

Backpropagationæ˜¯åœ¨Deep Leaning Modelä¸­è¨ˆç®—Gradientçš„æ–¹æ³•ï¼Œåœ¨è¨ˆç®—ä¹‹å‰æˆ‘å€‘è¦å…ˆäº†è§£å¾®ç©åˆ†çš„Chain Ruleã€‚

> Chain Rule:

å¦‚æœæœ‰å…©å€‹functionå¦‚ä¸‹

$$
\begin{aligned}
y &= g(x) \\
z &= h(y)
\end{aligned}
$$

å‰‡ $x$ å° $z$ çš„å¾®åˆ†å¦‚ä¸‹ï¼š

$$
\frac{\mathrm{d}z}{\mathrm{d}x} = \frac{\mathrm{d}z}{\mathrm{d}y} \cdot \frac{\mathrm{d}y}{\mathrm{d}x}
$$

åˆå¦‚æœæœ‰ä¸€å€‹å€¼ $s$ åŒæ™‚å½±éŸ¿ $x$ å’Œ $y$, è€Œ $x$ å’Œ $y$ åˆå½±éŸ¿ $z$ :

$$
\begin{aligned}
x &= g(s) \\
y &= h(s) \\
z &= k(x,y)
\end{aligned}
$$

å‰‡ $s$ å° $z$ çš„å¾®åˆ†å¦‚ä¸‹

$$
\frac{\mathrm{d}z}{\mathrm{d}s} = \frac{\partial{z}}{\partial{x}} \cdot \frac{\mathrm{d}x}{\mathrm{d}s} + \frac{\partial{z}}{\partial{y}} \cdot \frac{\mathrm{d}y}{\mathrm{d}s}
$$

æ¥è‘—æˆ‘å€‘å…ˆå®šç¾©æ·±åº¦å­¸ç¿’æ¨¡å‹æœƒè¦ä½¿ç”¨çš„å¹¾å€‹function:
>activation function ç”¨sigmoid function

$$
a = \sigma_{z}
$$

> å¡«å…¥activation functionä¸­çš„ $z$ å¦‚ä¸‹

$$
z = x_1w_1 +x_2w_2 +b
$$

> loss function ç”¨ Cross Entropy

$$
L(\theta) = \sum_{n=1}^{N} C^n(\theta)
$$

> ä¹Ÿå¯ä»¥æ”¹å¯«å¦‚ä¸‹


$$
\frac{\partial L(\theta)}{\partial w} = \sum_{n=1}^{N} \frac{\partial c^n(\theta)}{\partial w}
$$



å¾ä¸‹åœ–å¯ä»¥çœ‹åˆ°å®Œæ•´çš„functioné‚è¼¯ï¼Œinput layerå‚³å…¥åƒæ•¸ $x_1$ , $x_2$ ,ä¸¦èˆ‡ $w_1$ , $w_2$ , $b$ çµ„æˆ $z$, å°‡ $z$ å¸¶å…¥ activation function $\sigma{(z)}$ ç”¢å‡º $a$, $a$ å†ä½œç‚ºä¸‹ä¸€å±¤layerçš„åƒæ•¸ã€‚

![åœ–ç‰‡](https://hackmd.io/_uploads/BkihfRo80.png)

ç‚ºäº†è¦æ›´æ–°åƒæ•¸ $w$ ï¼Œæˆ‘å€‘éœ€è¦ç”¨ $w$ å°Loss functionåšåå¾®åˆ†ï¼Œä¾ç…§chain ruleå¦‚ä¸‹ï¼š

$$
\frac{\partial{C}}{\partial{w}} = \frac{\partial{z}}{\partial{w}} \cdot \frac{\partial{C}}{\partial{z}}
$$

è€Œæˆ‘å€‘å¯ä»¥è¼•æ˜“çŸ¥é“ $\frac{\partial{z}}{\partial{w_1}}$ å°±æ˜¯ $x_1$ ï¼Œè€Œé€™å€‹ $x_1$ å¾ä¸Šä¸€å±¤å‚³éä¾†çš„ï¼Œå› æ­¤ä¹Ÿå«åšå‰å‘å‚³æ’­ã€‚

> å‰å‘å‚³æ’­ (Forward Propagation)

$$
\begin{aligned}
\frac{\partial{z}}{\partial{w_1}} = x_1 \\
\frac{\partial{z}}{\partial{w_2}} = x_2
\end{aligned}
$$

è€Œ $\frac{\partial{C}}{\partial{w}}$ å¾Œé¢çš„éƒ¨åˆ†æ˜¯:

$$
\frac{\partial{C}}{\partial{z}} = \frac{\partial{a}}{\partial{z}} \cdot \frac{\partial{C}}{\partial{a}}
$$

å…¶ä¸­activation function $\sigma(z)$ çš„å¾®åˆ†å·²çŸ¥ï¼š

$$
\frac{\partial{a}}{\partial{z}} = \sigma'(z)
$$

è€Œ $\frac{\partial{C}}{\partial{a}}$ åˆå¯ä»¥ç¹¼çºŒå¦‚ä¸‹(å› ç‚º$a$å‡ºä¾†çš„å€¼åˆæœƒå‘ä¸‹å½±éŸ¿åˆ°ä¸‹ä¸€å±¤çš„åƒæ•¸function $z'$ å’Œ $z''$ )

> Chain Rule

$$
\frac{\partial{C}}{\partial{a}} = \frac{\partial{z'}}{\partial{a}} \cdot \frac{\partial{C}}{\partial{z'}} + \frac{\partial{z''}}{\partial{a}} \cdot \frac{\partial{C}}{\partial{z''}}
$$

å¾ä¸Šé¢çš„åœ–ç‰‡æˆ‘å€‘å¯ä»¥çŸ¥é“

$$
\begin{aligned}
\frac{\partial{z'}}{\partial{a}} = w_1 \\
\frac{\partial{z''}}{\partial{a}} = w_2
\end{aligned}
$$

é›–ç„¶ $\frac{\partial{C}}{\partial{z'}}$ å’Œ $\frac{\partial{C}}{\partial{z''}}$ ä»ç„¶æœªçŸ¥ï¼Œä½†æˆ‘å€‘å…ˆå‡è¨­æˆ‘å€‘çŸ¥é“æ€éº¼ç®—ï¼Œå¯ä»¥å¾ä¸Šé¢çš„ç®—æ˜¯ä¸­å¾—å‡º

$$
\frac{\partial{C}}{\partial{z}} = \sigma'(x)\left[w_3 \cdot \frac{\partial{C}}{\partial{z'}} + w_4\cdot \frac{\partial{C}}{\partial{z''}}\right]
$$

æœ€å¾Œå‡è¨­ $z'$ å’Œ $z''$ ä¸‹ä¸€å±¤å°±æ˜¯é€²å…¥Output layerä¸¦ç”¢å‡ºé æ¸¬çš„çµæœ $y_1$ å’Œ $y_2$ , ä¸¦æœ‰ç›¸å°æ‡‰çš„ç­”æ¡ˆ(Ground Truth) $\hat{y}_1$ å’Œ $\hat{y}_2$ ï¼Œæˆ‘å€‘ä¾¿å¯ä»¥ç®—å‡º $\frac{\partial{C}}{\partial{z'}}$ å’Œ $\frac{\partial{C}}{\partial{z''}}$ :


$$
\begin{aligned}
\frac{\partial{C}}{\partial{z'}} = \frac{\partial{y_1}}{\partial{z'}} \cdot \frac{\partial{C}}{\partial{y_1}} \\
\frac{\partial{C}}{\partial{z''}} = \frac{\partial{y_2}}{\partial{z''}} \cdot \frac{\partial{C}}{\partial{y_2}}
\end{aligned}
$$

è€Œæˆ‘å€‘çŸ¥é“äº† $\frac{\partial{C}}{\partial{z'}}$ å’Œ $\frac{\partial{C}}{\partial{z''}}$ å°±å¯ä»¥ç®—å‡º $\frac{\partial{C}}{\partial{z}}$ :

$$
\frac{\partial{C}}{\partial{z}} = \sigma'(x)\left[w_3 \cdot \frac{\partial{y_1}}{\partial{z'}} \cdot \frac{\partial{C}}{\partial{y_1}} + w_4\cdot \frac{\partial{y_2}}{\partial{z''}} \cdot \frac{\partial{C}}{\partial{y_2}}\right]
$$


å†æ­é…å‰å‘å‚³æ’­çš„ $x_1$ å¯ä»¥çµ„å‡ºä¾†ï¼š

$$
\frac{\partial{C}}{\partial{w_1}} = x_1 \cdot \frac{\partial{C}}{\partial{z}} \cdot \sigma'(x)\left[w_3 \cdot \frac{\partial{y_1}}{\partial{z'}} \cdot \frac{\partial{C}}{\partial{y_1}} + w_4\cdot \frac{\partial{y_2}}{\partial{z''}} \cdot \frac{\partial{C}}{\partial{y_2}}\right]
$$

æˆ‘å€‘å°±å¯ä»¥ç”¨ $\frac{\partial{C}}{\partial{w_1}}$ å»èª¿æ•´ $w_1$ äº†


# 3. Embedding èˆ‡ å‘é‡è³‡æ–™åº«

> åƒè€ƒè³‡æ–™ï¼š
> - [æ¥µé€ŸChatGPTé–‹ç™¼è€…å…µå™¨æŒ‡å—ï¼šè·¨ç•Œæ•´åˆPrompt Flowã€LangChainèˆ‡Semantic Kernelæ¡†æ¶](https://www.books.com.tw/products/0010987469)
> - [TinyMurky/embed_and_vector_database_practice](https://github.com/TinyMurky/embed_and_vector_database_practice)

## Embedding

Embedding æ˜¯å¤§å‹èªè¨€æ¨¡å‹é–‹ç™¼ä¸­çš„ä¸€å€‹é‡è¦é—œéµæŠ€è¡“ï¼Œå¯ä»¥å°‡æ–‡å­—è½‰æˆä¾ç…§å‘é‡ (vector)çš„æ–¹å¼å­˜åœ¨ï¼Œæ–¹ä¾¿è¼¸å…¥åˆ°æ·±åº¦å­¸ç¿’çš„æ¨¡å‹ä¸­ã€‚ç¶“ç”±ç‰¹æ®ŠEmbeddingæ¨¡å‹embedå¾Œçš„æ–‡å­—ï¼Œé‚„å¯ä»¥è®“é¡ä¼¼è©æ„çš„æ–‡å­—åœ¨å‘é‡ç©ºé–“ä¸­åœ¨ä¸€èµ·ã€‚Embeddingä¹Ÿä¸ä¸€å®šè¦é™åˆ¶åœ¨è©ï¼Œä¹Ÿå¯ä»¥é‡å°æ•´å€‹å¥å­çš„å¥ç¾©æŠ½å–å‡ºè¨Šæ¯è®Šæˆ vector (åƒæ˜¯Openai å¯ä»¥æä¾›å°‡å¥å­è®Šæˆ 1,536ç‚ºåº¦çš„å‘é‡)

### One-hot encoding
æœ€ç°¡å–®çš„Embeddingæ˜¯ one-hard encodingï¼Œå°±æ˜¯ä¸€å€‹è·Ÿå­—å…¸ä¸€æ¨£é•·çš„vectorï¼Œåœ¨è©²è©çš„ä½ç½®ä¸Šæ¨™ä¸Š1ï¼Œå…¶ä»–éƒ½æ˜¯0ã€‚
ä¾‹å¦‚ `ä½ å¥½å—ï¼Ÿ` å°±å¯ä»¥è®Šæˆ `ä½ `, `å¥½`, `å—`çš„å­—å…¸ï¼Œä¸¦è¡¨ç¤ºå¦‚ä¸‹ï¼š
1. ä½ ï¼š`[1, 0, 0]`
2. å¥½ï¼š`[0, 1, 0]`
3. å—ï¼š`[0, 0, 1]`

é€™æ¨£çš„å¥½è™•æ˜¯å¾ˆå¥½Embeddingï¼Œå£è™•æ˜¯vectoræœƒè®Šå¾—å¤ªé•·ã€‚

### Hugging Face

æˆ‘å€‘å¯ä»¥ç”¨Hugging facä¸Šçš„æ¨¡å‹`all-MiniLM-L6-v2`ä¾†åšembedï¼Œä»–æœƒæŠŠä¸€æ•´å€‹å¥å­ç›´æ¥æŠ½å–æˆ 384ç‚ºåº¦çš„å‘é‡ï¼Œå¦‚ä¸‹é¢æ‰€è¡¨ç¤º

```python
from sentence_transformers import SentenceTransformer

class EmbeddingModel:
    """
    this class is responsible for the embedding model
    """

    def __init__(self, model_name="sentence-transformers/all-MiniLM-L6-v2"):
        self.model: SentenceTransformer = SentenceTransformer(model_name)

    def encode(self, text: list[str]):
        """
        change the texts into embeddings
        """
        return self.model.encode(text)
```

ä¸‹é¢æˆ‘å€‘å°‡ä¸‰å€‹å¥å­åšEmbed
```python
def main():
    embedding_model = EmbeddingModel()
    sentences = ["Hello, World!", "I am Bob!", "I am a Sailer!"]

    embeddings = embedding_model.encode(sentences)
    print("Dimension: ", len(embeddings[0]))  # 384 å€‹å‘é‡
    print("embeddings: ", embeddings)
```

å¾—åˆ°ä¸‹é¢çµæœï¼Œä¸‰å€‹é•·åº¦ç‚º384çš„ float list
```
Dimension:  384

embeddings:  [[-0.03817715  0.03291114 -0.0054594  ... -0.04089032  0.03187141
   0.0181632 ]
 [-0.00832368  0.01277426 -0.0160365  ... -0.00265296 -0.03738691
  -0.12214652]
 [-0.0789836   0.02056168  0.04710546 ... -0.02807564 -0.0359869
   0.02323696]]
```

### å‘é‡è³‡æ–™åº«

å‘é‡è³‡æ–™åº«å¯ä»¥æŠŠEmbeddingå¾Œçš„vectorç•¶ä½œkeyï¼Œä¸¦åœ¨è£¡é¢å­˜æ”¾è³‡æ–™ã€‚ä¸¦ä¸”å¯ä»¥è—‰ç”±å‘é‡çš„ç›¸ä¼¼ç¨‹åº¦ä¾†æœå°‹å‡ºç›¸ä¼¼çš„è³‡æ–™ï¼Œä¸»è¦ç”¨åœ¨æ¨è–¦ç³»çµ±ï¼Œå¤§å‹èªè¨€æ¨¡å‹çš„RAGæ™‚ä½¿ç”¨ç­‰ã€‚

#### Qdrant

å‘é‡è³‡æ–™åº«æœ‰å¾ˆå¤šç¨®ï¼Œä¸‹é¢ä»‹ç´¹[Qdrant](https://qdrant.tech/), Qdrantæ˜¯é–‹æºçš„Rustèªè¨€å¯«æˆçš„å‘é‡è³‡æ–™åº«ï¼Œä¸¦ä¸”å¯ä»¥åœ¨æœ¬åœ°ç«¯ç”¨dockeræ¶è¨­

##### docker compose

docker-compose.yml å¦‚ä¸‹è¨­å®š
```yml
services:
  qdrant:
    image: qdrant/qdrant:v1.6.1
    restart: always
    container_name: qdrant
    ports:
      - "6333:6333"
    volumes:
      - ./qdrant/storage:/qurant/storage
      - ./qdrant/config.yaml:/qurant/config/production.yaml
```

ä¸Šé¢æ¯”è¼ƒé‡è¦çš„æ˜¯ volumnçš„è¨­å®šã€‚
- `/qurant/storage`ï¼šæ˜¯è¨­å®šå‘é‡è³‡æ–™åº«çœŸå¯¦çš„æª”æ¡ˆæ˜¯è¦å­˜åœ¨ä½ çš„é›»è…¦è£¡é¢çš„å“ªè£¡ï¼Œæˆ‘å°±æ˜¯å­˜åœ¨å°ˆæ¡ˆè³‡æ–™å¤¾ä¸‹é¢çš„ `./qdrant/storage` è³‡æ–™å¤¾
- `/qurant/config/production.yaml`ï¼šæ˜¯è¨­å®šQdrand configæª”åœ¨ä½ çš„é›»è…¦ä¸Šçš„çœŸå¯¦ä½ç½®ï¼Œåƒæ˜¯æˆ‘çš„å°±æ˜¯åœ¨å°ˆæ¡ˆè³‡æ–™å¤¾ä¸‹é¢çš„ `./qdrant/config.yaml`ã€‚
    - config.yamlä¸‹è¼‰ï¼š[é»æˆ‘](https://github.com/qdrant/qdrant/blob/master/config/config.yaml)


å¦å¤–åœ¨config.yamlæ‰¾åˆ° ä¸‹é¢é€™å€‹éƒ¨ä»½å¯ä»¥è¨­å®šå¯†ç¢¼
```yaml
service:
  api_key: your_secret_api_key_here
```

æ¥è‘—åœ¨comand lineä¸­è¼¸å…¥ä¸‹é¢æŒ‡ä»¤å°±å¯ä»¥å•Ÿç”¨äº†
```
docker-compose up -d
```

##### Qdrand Python SDK

Qdrandæœ‰æä¾›Python çš„SDKï¼Œå¯ä½¿ç”¨pipä¸‹è¼‰
```
poetry add qdrant-client openai
```

ä»¥ä¸‹çš„æ˜¯å®Œæ•´çš„ç¨‹å¼ç¢¼ï¼Œè§£èªªåœ¨å¾Œé¢

```python
from app.embedding.model import EmbeddingModel
from qdrant_client import QdrantClient
from qdrant_client.http import models
from qdrant_client.http.models import PointStruct


class QdrantSingleton:
    _instance = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super(QdrantSingleton, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not QdrantSingleton._initialized:
            self.qdrant_client = QdrantClient(
                url="http://localhost",
                port=6333,
                # api_key="api_key",
            )
            self.embedding_model = EmbeddingModel()
            QdrantSingleton._initialized = True

    def recreate_collection(self, collection_name: str):
        """
        é€™å€‹æ–¹æ³•æœƒé‡æ–°å»ºç«‹collectionï¼Œä¸¦è¨­å®šcollectionçš„åƒæ•¸
        https://ithelp.ithome.com.tw/articles/10335513
        """
        # https://python-client.qdrant.tech/qdrant_client.http.models.models#qdrant_client.http.models.models.VectorParams
        # ä¸€å€‹ç”¨cosineç®—è·é›¢çš„å‘é‡ï¼Œé•·åº¦æ˜¯384
        vectors_config = models.VectorParams(
            distance=models.Distance.COSINE,
            size=384,
        )

        # mä»£è¡¨æ¯å€‹ç¯€é»è¿‘é„°æ•¸é‡ã€‚må€¼è¶Šå¤§ï¼ŒæŸ¥è©¢é€Ÿåº¦è¶Šå¿«ï¼Œä½†å…§å­˜å’Œæ§‹å»ºæ™‚é–“ä¹Ÿæœƒå¢åŠ ã€‚
        # ef_constructé€™æ˜¯ç”¨æ–¼æ§‹å»ºåœ–æ™‚çš„æ•ˆç‡åƒæ•¸ã€‚è¼ƒå¤§çš„ef_constructå€¼æœƒå°è‡´æ›´å¥½çš„æŸ¥è©¢å“è³ªï¼Œä½†æœƒå¢åŠ æ§‹å»ºæ™‚é–“ã€‚ä»£è¡¨åœ¨æ§‹å»ºç´¢å¼•æ™‚æœç´¢çš„ç¯€é»æ•¸é‡
        hnsw_config = models.HnswConfigDiff(on_disk=True, m=16, ef_construct=100)

        # memmap_thresholdæ˜¯é€™è¡¨ç¤ºç•¶æ•¸æ“šå¤§å°è¶…é20000æ™‚ï¼Œå°‡ä½¿ç”¨å…§å­˜æ˜ å°„ä¾†ç®¡ç†æ•¸æ“šï¼Œé€™å¯ä»¥æœ‰æ•ˆåœ°è™•ç†å¤§é‡æ•¸æ“šä¸¦æ¸›å°‘å…§å­˜ä½¿ç”¨ã€‚
        optimizers_config = models.OptimizersConfigDiff(memmap_threshold=20000)

        self.qdrant_client.recreate_collection(
            collection_name=collection_name,
            vectors_config=vectors_config,
            hnsw_config=hnsw_config,
            optimizers_config=optimizers_config,
        )
        return self.qdrant_client

    def create_collection(self, collection_name: str):
        """
        create collection
        """
        vectors_config = models.VectorParams(
            distance=models.Distance.COSINE,
            size=384,
        )

        hnsw_config = models.HnswConfigDiff(on_disk=True, m=16, ef_construct=100)

        optimizers_config = models.OptimizersConfigDiff(memmap_threshold=20000)
        if not self.qdrant_client.collection_exists(collection_name):
            self.qdrant_client.create_collection(
                collection_name=collection_name,
                vectors_config=vectors_config,
                hnsw_config=hnsw_config,
                optimizers_config=optimizers_config,
            )
        return self.qdrant_client

    def get_embedding(self, text: str) -> list[float]:
        """
        get embedding
        """
        embedding_list = self.embedding_model.encode([text])
        embedding = embedding_list[0]
        embedding_to_float_list = embedding.tolist()
        return embedding_to_float_list

    def upsert_vectors(
        self, vectors: list[list[float]], collection_name: str, data: list
    ):
        """
        upsert vectors
        payload is metadata, can be any data in dict
        """
        for i, vector in enumerate(vectors):
            self.qdrant_client.upsert(
                collection_name=collection_name,
                points=[
                    PointStruct(
                        id=i,
                        vector=vector,
                        payload=data[i],
                    )
                ],
            )
        print("upsert_vectors done")

    def search_for_qdrant(self, text: str, collection_name: str, limit_k: int):
        """
        search for qdrant
        """
        embedding_vector = self.get_embedding(text)
        search_result = self.qdrant_client.search(
            collection_name=collection_name,
            query_vector=embedding_vector,
            limit=limit_k,
            append_payload=True,
        )
        return search_result
```

é€™é‚Šçœ‹èµ·ä¾†å«è¤‡é›œï¼Œä½†å…¶å¯¦é€™å€‹æ˜¯pythonçš„Singletonçš„å¯«æ³•ï¼Œåœ¨å‘¼å«é€™å€‹classçš„æ™‚å€™éƒ½åªæœƒå›å‚³åŒä¸€å€‹initã€‚æœ€é‡è¦çš„æ˜¯`QdrantClient`ï¼Œé€™è£¡è¦æ”¾å’ŒQdrantçš„é€£ç·šè³‡è¨Šï¼Œå¦å¤–EmbeddingModelå‰‡æ˜¯ä¸Šé¢çš„Classå¼•å…¥ã€‚
```python
class QdrantSingleton:
    _instance = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super(QdrantSingleton, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not QdrantSingleton._initialized:
            self.qdrant_client = QdrantClient(
                url="http://localhost",
                port=6333,
                # api_key="api_key",
            )
            self.embedding_model = EmbeddingModel()
            QdrantSingleton._initialized = True
```

æ¥è‘—æˆ‘å€‘è¦åœ¨å‘é‡è³‡æ–™åº«ä¸­å»ºç«‹ä¸€å€‹collectionï¼Œcollectionå°±åƒæ˜¯ä¸€èˆ¬è³‡æ–™åº«çš„table,ç”¨ä¾†å­˜æ”¾æˆ‘å€‘çš„è³‡æ–™ï¼Œç”±æ–¼æ˜¯ç·´ç¿’ï¼Œæˆ‘é¸æ“‡ä½¿ç”¨`recreate_collection`ï¼Œé€™æ¨£å¦‚æœå‘¼å«æ’åçš„collectionå°±å¯ä»¥å…ˆåˆªé™¤å†é‡æ–°å‰µä¸€å€‹ï¼Œå¦‚æœä¸æƒ³ä¸€ç›´åˆªé™¤ä¹Ÿå¯ä»¥é¸æ“‡ä¸Šé¢çš„`create_collection`

åœ¨é€™è£¡æˆ‘å€‘å¯ä»¥ç”¨`VectorParams`è¨­å®šå‘é‡ä¹‹é–“çš„è·é›¢æ€éº¼ç®—ï¼Œæˆ‘é¸æ“‡COSINEï¼Œä¹Ÿå¯ä»¥ç”¨`models.Distance.EUCLID`é¸æ“‡å…©é»ç›´ç·šè·é›¢ã€‚

ä¸¦ä¸”`VectorParams`é‚„å¯ä»¥è¨­å®šç•¶ä½œkeyçš„vectorçš„é•·åº¦æœ‰å¤šé•·ï¼Œå› ç‚ºæˆ‘ä½¿ç”¨Hugging faceçš„`all-MiniLM-L6-v2`å›ºå®šæœƒç”¢ç”Ÿ 384 ç¶­åº¦çš„vectorï¼Œæ‰€ä»¥å¯«384
```python
  def recreate_collection(self, collection_name: str):
        """
        é€™å€‹æ–¹æ³•æœƒé‡æ–°å»ºç«‹collectionï¼Œä¸¦è¨­å®šcollectionçš„åƒæ•¸
        https://ithelp.ithome.com.tw/articles/10335513
        """
        # https://python-client.qdrant.tech/qdrant_client.http.models.models#qdrant_client.http.models.models.VectorParams
        # ä¸€å€‹ç”¨cosineç®—è·é›¢çš„å‘é‡ï¼Œé•·åº¦æ˜¯384
        vectors_config = models.VectorParams(
            distance=models.Distance.COSINE,
            size=384,
        )

        # mä»£è¡¨æ¯å€‹ç¯€é»è¿‘é„°æ•¸é‡ã€‚må€¼è¶Šå¤§ï¼ŒæŸ¥è©¢é€Ÿåº¦è¶Šå¿«ï¼Œä½†å…§å­˜å’Œæ§‹å»ºæ™‚é–“ä¹Ÿæœƒå¢åŠ ã€‚
        # ef_constructé€™æ˜¯ç”¨æ–¼æ§‹å»ºåœ–æ™‚çš„æ•ˆç‡åƒæ•¸ã€‚è¼ƒå¤§çš„ef_constructå€¼æœƒå°è‡´æ›´å¥½çš„æŸ¥è©¢å“è³ªï¼Œä½†æœƒå¢åŠ æ§‹å»ºæ™‚é–“ã€‚ä»£è¡¨åœ¨æ§‹å»ºç´¢å¼•æ™‚æœç´¢çš„ç¯€é»æ•¸é‡
        hnsw_config = models.HnswConfigDiff(on_disk=True, m=16, ef_construct=100)

        # memmap_thresholdæ˜¯é€™è¡¨ç¤ºç•¶æ•¸æ“šå¤§å°è¶…é20000æ™‚ï¼Œå°‡ä½¿ç”¨å…§å­˜æ˜ å°„ä¾†ç®¡ç†æ•¸æ“šï¼Œé€™å¯ä»¥æœ‰æ•ˆåœ°è™•ç†å¤§é‡æ•¸æ“šä¸¦æ¸›å°‘å…§å­˜ä½¿ç”¨ã€‚
        optimizers_config = models.OptimizersConfigDiff(memmap_threshold=20000)

        self.qdrant_client.recreate_collection(
            collection_name=collection_name,
            vectors_config=vectors_config,
            hnsw_config=hnsw_config,
            optimizers_config=optimizers_config,
        )
        return self.qdrant_client
```
å‘¼å«ä¹‹å¾Œé€²å…¥[localhost:6333/dashboard](http://localhost:6333/dashboard)æ‡‰è©²å¯ä»¥çœ‹åˆ°ä¸‹é¢çš„é¢
![image](https://hackmd.io/_uploads/ByymCXEIA.png)

ä»¥ä¸‹å‰‡æ˜¯åˆ©ç”¨Hugging faceçš„`all-MiniLM-L6-v2`å°‡æ–‡å­—ç”¢å‡ºvectorï¼Œæˆ‘è¨­è¨ˆæˆä¸€æ¬¡ç”¨ä¸€å€‹å¥å­embeddingï¼Œä½†è¦æ³¨æ„å›å‚³çš„embeddingæœƒæ˜¯ tensor, shapeæ˜¯(1, 384)ï¼Œæ‰€ä»¥è¦æ‹¿å‡ºç¬¬0å€‹ä¹‹å¾Œå‘¼å«to_listï¼Œè½‰æˆfloat arrayå¾Œæ‰èƒ½æ”¾å…¥Qdrant
```python
    def get_embedding(self, text: str) -> list[float]:
        """
        get embedding
        """
        embedding_list = self.embedding_model.encode([text])
        embedding = embedding_list[0]
        embedding_to_float_list = embedding.tolist()
        return embedding_to_float_list
```

æ¥è‘—å¯ä»¥ç”¨upsert(å…¶å¯¦insertä¹Ÿå¯ä»¥)çš„æ–¹æ³•ï¼ŒæŠŠvectorç•¶ä½œkey, dataç•¶ä½œvalue(åœ¨Qdrantè£¡é¢å«åšpayload)ï¼Œdataå¯ä»¥æ˜¯ä»»ä½•å‹æ…‹çš„è³‡æ–™çµ„æˆçš„arrayï¼Œåƒæ˜¯python çš„dictionary, æœƒå­˜æˆjsonçš„å½¢å¼
```python
    def upsert_vectors(
        self, vectors: list[list[float]], collection_name: str, data: list
    ):
        """
        upsert vectors
        payload is metadata, can be any data in dict
        """
        for i, vector in enumerate(vectors):
            self.qdrant_client.upsert(
                collection_name=collection_name,
                points=[
                    PointStruct(
                        id=i,
                        vector=vector,
                        payload=data[i],
                    )
                ],
            )
        print("upsert_vectors done")
```

æœ€å¾Œæ˜¯æŸ¥è©¢ï¼Œåªè¦æä¾›ä¸€æ®µæ–‡å­—ï¼Œæœƒå…ˆé€²è¡Œembedä¹‹å¾Œï¼Œç”¨é€™å€‹vectorå»è³‡æ–™åº«æŸ¥è©¢ï¼Œä¸¦æŸ¥å‡ºæœ€æ¥è¿‘çš„`limit_k`çš„è³‡æ–™ï¼Œç„¶å¾ŒæŠŠè£¡é¢çš„payloadæ‹¿å‡ºä¾†ã€‚
```python
    def search_for_qdrant(self, text: str, collection_name: str, limit_k: int):
        """
        search for qdrant
        """
        embedding_vector = self.get_embedding(text)
        search_result = self.qdrant_client.search(
            collection_name=collection_name,
            query_vector=embedding_vector,
            limit=limit_k,
            append_payload=True,
        )
        return search_result
```

##### Qdrantå¯¦æˆ°æ¼”ç·´

ä»¥ä¸‹æ˜¯æˆ‘æœ‰`American Idiots`å‰å››å¥çš„æ­Œè©ï¼Œæˆ‘å€‘æŠŠä»–ä¸€å€‹ä¸€å€‹embedå¥½ï¼Œå†ç”¨embedçš„vectorç•¶ä½œkey, æŠŠæ­Œè©çš„è³‡æ–™ç•¶ä½œpayloadå­˜åœ¨å‘é‡è³‡æ–™åº«
```python
def main():

    # qdrant
    drunken_sailer = [
        {"id": "1", "lyric": "What will we do with a drunken sailor"},
        {"id": "2", "lyric": "Early in the morning"},
        {"id": "3", "lyric": "Way hay and up she rises"},
        {"id": "4", "lyric": "have his belly with a rusty razor"},
        {"id": "5", "lyric": "Put him in a long boat till his sober"},
    ]

    qdrant = QdrantSingleton()
    collection_name = "Lyrics"
    qdrant.recreate_collection(collection_name)

    embedding_array = [qdrant.get_embedding(text["lyric"]) for text in drunken_sailer]

    qdrant.upsert_vectors(embedding_array, collection_name, drunken_sailer)
```

åœ¨ [localhost:6333/dashboard](http://localhost:6333/dashboard)ä¸­å¯ä»¥çœ‹åˆ°å·²ç¶“å­˜é€²å»äº†ã€‚

![image](https://hackmd.io/_uploads/B1oYkr4IC.png)


æ¥è‘—æˆ‘å€‘ç”¨ä¸€å¥è©±é€²å»æœæŸ¥ï¼Œä¸¦ä¸”è¨­å®šæˆ‘å€‘åªæƒ³è¦æ‰¾åˆ°æœ€ç›¸è¿‘çš„ä¸€å€‹å€¼

```python
    query_text = "Is drunken sailor a good song?"
    search_result = qdrant.search_for_qdrant(query_text, collection_name, limit_k=1)

    print(f"å°‹æ‰¾: {query_text}", search_result)
```
outputå¯ä»¥çœ‹åˆ°æœ€æ¥è¿‘çš„æ­Œè©æ˜¯`"Don't wanna be an American idiot"`
```
å°‹æ‰¾: Is drunken sailor a good song? [ScoredPoint(id=0, version=0, score=0.58723116, payload={'id': '1', 'lyric': 'What will we do with a drunken sailor'}, vector=None, shard_key=None)]
```
